{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "093bf7e4",
   "metadata": {},
   "source": [
    "# Data Analysis A Bayesian Tutorial\n",
    "\n",
    "working out of Second Edition by D.S. Sivia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79cc53a",
   "metadata": {},
   "source": [
    "Baye's Theorem: \n",
    "$$\\begin{equation}\n",
    "\\label{eq:bayes}\n",
    "P(\\theta|\\textbf{D},I) = P(D|\\theta,I ) \\frac{P(\\theta| I)}{P(\\textbf{D}| I)}\n",
    "\\end{equation}$$\n",
    "Where $\\theta$ is a parameter in a model described by I and D is the data.\n",
    "\n",
    "In the case of beginning with a set of data points $(x_i,y_i\\pm \\sigma_y)$, where the uncertainty on y is a constant for each data point. y_i also has some error in the measurement, desrcibed by a Gaussian around the true value $\\hat{y_i}$ and the uncertainty on $\\sigma_y$.\n",
    "\n",
    "In other words, $y_i=\\hat{y_i}+\\epsilon$ and $\\epsilon$ follows a Normal distribution about $\\hat{y_i}$.\n",
    "\n",
    "It is known that the relationship between the true values that we are trying to measure is $\\hat{y_i}=f(\\hat{x_i})=a\\hat{x_i}+b.$ a and b are the parameters that I will try to estimate using Baye's theorem. \n",
    "\n",
    "The probability of getting a value $y_i$ given $x_i$,a, and b is then given by a Gaussian:\n",
    "\n",
    "$P(y_i|x_i,a,b,I)=N(ax_i+b,\\sigma_y)$\n",
    "\n",
    "If I assume a flat prior (no inital preference for the values of a and b) since I have not seen the data, the prior term can be neglected. Further, if I am estimating parameters and do not care about the true value of $P(\\theta|\\textbf{D},I)$ then the evidence can also be neglected. \n",
    "\n",
    "This yields $P(\\theta|\\textbf{D},I) = P(D|\\theta,I )$\n",
    "This is the beauty of Baye's theorem since it will be easier to determine the evidence than the posterior.\n",
    "\n",
    "For each data point k in the N amount of data the likelihood can be calculated. For the overall likelihood these can be multiplied. \n",
    "Solving analytically, one can find that \n",
    "$P(\\theta|\\textbf{D},I) = P(D|\\theta,I )=\\prod_{k=1}^{N}\\frac{1}{\\sigma_y\\sqrt{2\\pi}}\\exp(\\frac{-(y_k-(ax_k+b))^2}{2\\sigma_y})$\n",
    "\n",
    "Now that I know my probability distribution for a given data, I simply need to find the a and b parameters in my model that make this most likely. This turns it into a $\\chi^2$ minimization problem. If I take the logarithm of P I get:\n",
    "$L(\\theta|\\textbf{D},I) = L(D|\\theta,I )=\\sum_{k=1}^{N}constant+(\\frac{-(y_k-(ax_k+b))^2}{2\\sigma_y})=\\sum_{k=1}^{N}constant+\\chi^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a0971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters, arrays\n",
    "a=2\n",
    "b=3\n",
    "sig_y=0.05\n",
    "data_len=10\n",
    "y_i=np.zeros(data_len)\n",
    "x_i=np.zeros(data_len)\n",
    "\n",
    "def y_hat(x_i):\n",
    "    return(a*x_i+b)\n",
    "\n",
    "pi=np.pi\n",
    "e=np.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f2dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create my Gaussian\n",
    "def gauss(x,y_data,sig_y,a,b):\n",
    "    return(1/(sig_y*np.sqrt(2*pi))*e**(-(y_data-(a*x+b))**2/(2*sig_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b88dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what does this look like?\n",
    "y_data=np.linspace(0,a*15)\n",
    "x_test=5\n",
    "g=gauss(x_test,y_data, sig_y,a,b)\n",
    "plt.plot(y_data,g)\n",
    "plt.xlabel(\"y value for given x\")\n",
    "plt.ylabel(\"probability\")\n",
    "print(\"mean is\", a*x_test+b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1893b6a",
   "metadata": {},
   "source": [
    "So now I have a gaussian that my noise for each data point should follow. For each point $x_k,y_k$ I will know $x_i$ but y_i will be drawn from this gaussian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115045fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create my x array, going to choose even spacing\n",
    "x_i=np.arange(0,data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e268d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "for i in range(len(x_i)):\n",
    "    mean=a*x_i[i]+b\n",
    "    sigma=sig_y\n",
    "\n",
    "    s = np.random.normal(mean, sigma, 1)\n",
    "    y_i[i]=s\n",
    "    \n",
    "#print(y_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d213e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_i,y_hat(x_i), label=\"true y value\")\n",
    "plt.errorbar(x_i,y_i, yerr=sig_y, fmt='o', label=\"measured value\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d79a11d",
   "metadata": {},
   "source": [
    "#now I need to fit for my unkown a and b parameter (this assumes I did not know a and b that generated my data)\n",
    "#essentially I am going to be performing a chi^2 test\n",
    "#this can be done analytically for this simple problem by taking derivatives of p\n",
    "#here I am showing a numerical solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521205d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_guess=np.linspace(a*0.8,a*1.2,500)\n",
    "b_guess=np.linspace(b*0.8,b*1.2,400)\n",
    "\n",
    "aa,bb=np.meshgrid(a_guess,b_guess)\n",
    "chi2vals = np.zeros(np.prod(aa.shape))\n",
    "\n",
    "\n",
    "def chi2(a_val, b_val,x_i,y_i,sig_y):\n",
    "    val=np.sum(((y_i-(a_val*x_i+b_val))/(sig_y))**2 )\n",
    "    return val\n",
    "\n",
    "# for i in range(len(a_guess)-1):\n",
    "#     for j in range(len(b_guess)-1):\n",
    "#         chi2valstest[i][j]=chi2(a_guess[i],b_guess[j],x_i,y_i,sig_y)\n",
    "\n",
    "for i,(ai,bi) in enumerate(zip(aa.flatten(),bb.flatten())):\n",
    "    chi2vals[i]=chi2(ai,bi,x_i,y_i,sig_y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3693d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp=ax.contour(a_guess,b_guess, chi2vals)\n",
    "\n",
    "# ax.clabel(cp, inline=True, \n",
    "#           fontsize=10)\n",
    "\n",
    "\n",
    "cp = plt.contourf(aa, bb, np.exp(-0.5*chi2vals.reshape(aa.shape)), levels = 1000)\n",
    "plt.colorbar(cp)\n",
    "#plt.imshow(a_guess, b_guess, chi2vals, cmap='hot')\n",
    "# import seaborn as sns\n",
    "#ax=sns.heatmap(chi2vals)\n",
    "plt.scatter(a,b, marker='+', c='r', lw = 0.9)\n",
    "plt.xlabel(\"a\")\n",
    "plt.ylabel(\"b\")\n",
    "# plt.title(\"$\\chi^2$ values for a and b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381ba256",
   "metadata": {},
   "source": [
    "So, as we can see $\\chi^2$ is minimized at the correct value of a and b, but this minimization occurs over a very long range. Next, I will test how our uncertainty effects this. If $\\sigma_y$ is smaller will our parameters be more well constrained?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fcd572",
   "metadata": {},
   "source": [
    "Surprisingly (are you really *that* surprised? -Ste-), this did not improve our constraint on a and b. \n",
    "\n",
    "I may have errors in this code.  (you definitely have. everyone has)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31921233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after this point still working on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f68b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #code from Walter Del Pozzo\n",
    "# def FindHeightForLevel(inArr, adLevels):\n",
    "#    \"\"\"\n",
    "#    Computes the height of a :math:`2D` function for given levels\n",
    "\n",
    "#    :param inArr: function values\n",
    "#    :type inArr: array\n",
    "#    :param adLevels: levels\n",
    "#    :type adLevels: list or array\n",
    "\n",
    "#    :return: function values with levels closest to *levels*\n",
    "#    :rtype: array\n",
    "#    \"\"\"\n",
    "\n",
    "#    # flatten the array\n",
    "#    oldshape = np.shape(inArr)\n",
    "#    adInput  = np.reshape(inArr,oldshape[0]*oldshape[1])\n",
    "#    #adInput=inArr\n",
    "\n",
    "#    # get array specifics\n",
    "#    nLength  = np.size(adInput)\n",
    "\n",
    "#    # create reversed sorted list\n",
    "#    adTemp   = -1.0 * adInput\n",
    "#    adSorted = np.sort(adTemp)\n",
    "#    adSorted = -1.0 * adSorted\n",
    "\n",
    "#    # create the normalised cumulative distribution\n",
    "#    adCum    = np.zeros(nLength)\n",
    "#    adCum[0] = adSorted[0]\n",
    "\n",
    "#    for i in range(1,nLength):\n",
    "#        adCum[i] = np.logaddexp(adCum[i-1], adSorted[i])\n",
    "\n",
    "#    adCum    = adCum - adCum[-1]\n",
    "\n",
    "#    # find the values closest to levels\n",
    "#    adHeights = []\n",
    "#    for item in adLevels:\n",
    "#        idx = (np.abs(adCum-np.log(item))).argmin()\n",
    "#        adHeights.append(adSorted[idx])\n",
    "\n",
    "#    adHeights = np.array(adHeights)\n",
    "#    return np.sort(adHeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e4731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from credibleregions import FindHeightForLevel as FHFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd2e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FHFL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34cde94",
   "metadata": {},
   "outputs": [],
   "source": [
    "levelval=(FHFL(np.log(chi2vals.reshape(aa.shape)),[0.9]))\n",
    "print(levelval)\n",
    "levelval=(levelval[0])\n",
    "print(levelval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a5deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(chi2vals.reshape(aa.shape))\n",
    "chi2matrix=chi2vals.copy()\n",
    "chi2matrix=chi2matrix.reshape(aa.shape)\n",
    "print(chi2matrix)\n",
    "# print(len(chi2matrix[:,0]))\n",
    "# print(aa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d102991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def selectrange(matrix1):\n",
    "    matrix=np.log(matrix1.copy())\n",
    "    for j in range(len(matrix[:,0])):\n",
    "        for k in range(len(matrix[0,:])):\n",
    "            if matrix[j][k]<=levelval:\n",
    "                matrix[j][k]=1\n",
    "                #print(j,k)\n",
    "            else:\n",
    "                matrix[j][k]=0\n",
    "    return matrix\n",
    "\n",
    "curvematrix=selectrange(chi2matrix)\n",
    "            \n",
    "curve90=plt.contourf(aa,bb, curvematrix)\n",
    "plt.colorbar(curve90)\n",
    "#plt.legend()\n",
    "plt.scatter(a,b, marker='+', c='r', lw = 0.9)\n",
    "plt.xlabel(\"a\")\n",
    "plt.ylabel(\"b\")\n",
    "#plt.colorbar(cp)\n",
    "\n",
    "\n",
    "#print(chi2matrix,\"and\", curvematrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa97e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "\n",
    "# #code from Walter Del Pozzo\n",
    "# def FindHeightForLevel(inArr, adLevels):\n",
    "#    \"\"\"\n",
    "#    Computes the height of a :math:`2D` function for given levels\n",
    "\n",
    "#    :param inArr: function values\n",
    "#    :type inArr: array\n",
    "#    :param adLevels: levels\n",
    "#    :type adLevels: list or array\n",
    "\n",
    "#    :return: function values with levels closest to *levels*\n",
    "#    :rtype: array\n",
    "#    \"\"\"\n",
    "\n",
    "#    # flatten the array\n",
    "#    oldshape = np.shape(inArr)\n",
    "#    adInput  = np.reshape(inArr,oldshape[0]*oldshape[1])\n",
    "#    #adInput=inArr\n",
    "\n",
    "#    # get array specifics\n",
    "#    nLength  = np.size(adInput)\n",
    "\n",
    "#    # create reversed sorted list\n",
    "#    adTemp   = -1.0 * adInput\n",
    "#    adSorted = np.sort(adTemp)\n",
    "#    adSorted = -1.0 * adSorted\n",
    "\n",
    "#    # create the normalised cumulative distribution\n",
    "#    adCum    = np.zeros(nLength)\n",
    "#    adCum[0] = adSorted[0]\n",
    "\n",
    "#    for i in range(1,nLength):\n",
    "#        adCum[i] = np.logaddexp(adCum[i-1], adSorted[i])\n",
    "\n",
    "#    adCum    = adCum - adCum[-1]\n",
    "\n",
    "#    # find the values closest to levels\n",
    "#    adHeights = []\n",
    "#    for item in adLevels:\n",
    "#        print(item) \n",
    "#        idx = (np.abs(adCum-np.log(item))).argmin()\n",
    "#        adHeights.append(adSorted[idx])\n",
    "\n",
    "#    adHeights = np.array(adHeights)\n",
    "#    return np.sort(adHeights), idx, adCum, adSorted, adCum[-1]\n",
    "\n",
    "# FindHeightForLevel(np.log(chi2vals.reshape(aa.shape)),[0.5, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65efa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
